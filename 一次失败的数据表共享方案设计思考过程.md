# 一次失败的数据表共享方案设计思考过程
　　最近一直在思考将项目中的策划填表数据在不同进程之间进行共享。
　　问题来源：
- 由于项目架构原因，现在策划数据在内存中加载时，存在对内存的极大浪费（预分配缘故无法对稀疏矩阵做压缩）
- 又由于项目的架构师面向进程而非服务的，又不愿意将逻辑不相干的服务强行合并到一个进程，因此存在相当多小进程
- 这样就出现了很多小进程，本身就几十M内存，但是一定要占用700+M的资源数据的奇特现象（据说后期会到2G以上）

　　因此我就思考将这些资源数据放到一块共享内存上，节约资源。

_ _ _

　　之前开会的时候大家讨论过这个方案，但是当时认为这样在reload的时候，有可能某个进程进行reload的同时另外一个进程还在读取，导致读到中间态的错误数据。
  
　　我后来想了下，如果由一个监护进程负责它的load跟reload（每个物理机一组），并且每次reload的时候先在另一块内存上执行reload，成功之后再把指向资源的指针指向新资源（双缓存），这样就可以避免中间态的问题。

_ _ _

　　解决这个问题之后，我又去梳理了一遍代码，发现又有新问题，资源模块里不少数据是用hashtable建过索引缓存的，这些hashtable里有记录不同的函数指针，而这些函数指针是指向不同进程的代码段的不同函数的，不可能一致。
  
　　如果要去掉这部分函数指针，那么一定需要这些hashtable的普通成员变量里不能有hash/compare函数的指针，思考良久，用下列方法也可以解决：
  
- 每次执行的时候传入hash/compare函数指针，由于资源的读取代码相对集中，这不是太大问题
- 或者在模板将这两个函数指针定义为static成员变量，然后在用到的地方才对这两个成员变量进行定义，但是这样会有一个问题，有模板实例化的缘故，一旦出现了两个同样参数类型的hashtable，就会导致冲突（例如item/skill都存在一个hashtable<int, int>的索引映射，那这两个其实是一个类，但是定义了两次hash函数）
- 将函数指针也作为模板参数传入，那每一处hashtable一定是单独实例化的一个类，不会出现冲突。

_ _ _

　　再继续想下去，就发现一个更大的无法解决的问题。
  
　　如果想让不同进程共享一份资源数据，那么就要做到每一个进程上资源的逻辑跟数据完全分离，共享的这部分只能有数据。但是每一个数据表本身就是一个存在多态的class，隐藏在背后的vtable就会导致逻辑跟跟状态无法完全分离。也就是一个class实例占用的内存空间里，一定既有逻辑（vtable）也有数据（普通成员变量）。除非将所有普通成员变量打包到一个POD的类里，然后持有指针（这个解决方案改动太大，预料是不会通过的）。
  
　　也就是说C++的class天然是对数据/逻辑分离存在一定障碍的，非POD的class是不能作为数据单元进行。
  
　　这样也能理解为什么IEG采用类似slab的组织方式进行预分配，而不是更灵活的直接改写new/delete/malloc/free的方式（从共享内存里分配释放）来执行了。因为进程挂掉拉起的时候，对旧数据执行再关联的时候必须重新将class的实例跟class再次映射上（重设vtable），slab的组织方式更容易做到这点，自由的new/delete可能需要建立某种在多次启动进程后仍生效的反射机制才可以。

_ _ _

　　再进一步想想，是不是只有Cpp这样，其他语言呢？python呢？
  
　　如果是C语言，应该实现结果跟Cpp把数据打包到POD类里差不多，作出彻底的数据-逻辑分离。
  
　　如果是python，共享的应该是内建的基础数据类型（甚至不需要全部，只需要int/float/string/tuple/dict五种即可）。YY一下，如果要做应该分这几步：
- 将五种基础类型稍稍修改下再封装成新的共享类型，主要是修改相互之间指针（例如dict里引用某个int，不能之间持有指针，应该持有地址偏移量，避免在不同进程之间失效）
- 对读取pyobject的ob_type的做一次封装即可（宏Py_TYPE），也就是对普通的object直接读ob_type，共享区的五种基础类型的pyobject读每个进程自己代码段的相应type。这相当于C++里对虚表的读取进行封装。


